{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.2–混入门.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggPascal/PYCMS-STEP-INTO/blob/master/1_2%E2%80%93%E6%B7%B7%E5%85%A5%E9%97%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYn2gUGM0Uq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7wkN8wR0ebz",
        "colab_type": "text"
      },
      "source": [
        "# 为啥叫混入门\n",
        "深度学习是一个新事物，因此它变化很快。  \n",
        "你无法弄明白深度学习的本质，因为这需要你理解高阶微积分。  \n",
        "所以，你是真的在混入门。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOquHvL21T2h",
        "colab_type": "text"
      },
      "source": [
        "# 最基础的东西\n",
        "虽然你无法理解微积分的一些细节，但是这也不影响你的开发。\n",
        "为了避免你无法读懂论文，我还是要教你一些基本的知识。\n",
        "## 词汇\n",
        "深度学习和浅度学习都会有一堆莫名其妙的专业词汇，为了保证通用性，本书会统一采用已规定的词汇表达。下面是一些基础词汇\n",
        "###向量 \n",
        "故名思义，就是有方向的量。  \n",
        "数学上面的向量是表示从起点到终点间的所有数字,含有正负之分。  \n",
        "\n",
        "### 轴\n",
        "英文Axis  \n",
        "是指如果向量沿着某一个确定的两点改变，两点之间所构成的直线便是该向量在向量空间里的轴。  \n",
        "轴在人工智能里普遍表示数据单方面的计量，比如RGB图像可以表示为在由R通道轴，G通道轴，B通道轴共同组成的向量坐标点中。\n",
        "\n",
        "### 梯度\n",
        "一种用于衡量信息差距的量，由微积分运算求得。  \n",
        "深度学习中的梯度是指权重梯度。\n",
        "\n",
        "## 理论\n",
        "虽然计算机帮助我们完成了复杂的部分，但是一些基础理论你必须学会。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4qU4g76I1MK",
        "colab_type": "text"
      },
      "source": [
        "## 神经网络的本质\n",
        "神经网络的本质是由多个虚拟神经元的计算表达组成的合集  \n",
        "每种神经元因其激活函数，内置公式不同，在各种不同的任务中有不同的表现。\n",
        "### 感知器\n",
        "最早的现代化神经元模型，直到20世纪40年代才被证明无法应对视觉任务的元祖模型。  \n",
        "我们将利用它的简化版本来讲一下神经元计算规则。\n",
        "简化版感知器输出方程：Output(x) = ax+b  \n",
        "其中a是神经元的权值，它会告诉我们这个神经元在这一层网络输出的贡献。       \n",
        "b是神经元的隐藏值。注意！这个参数是可选的，大部分情况下是神经元和自己的阀值直接比较。\n",
        "\n",
        "计算遵照以下步骤执行：\n",
        "\n",
        "\n",
        "1.   接受来自其他神经元或者数据输入，可能会使用一些函数来使输入化为零维（数字）。\n",
        "2.   乘以神经元的权重，如果要求加上隐藏值，也会在这一步完成。\n",
        "3. 与自己的阀值比较，如果大于或等于自己的阀值，那么就输出1，如果不是，就输出0\n",
        "4. 重复上述步骤，直到抵达网络的最后一层  \n",
        "\n",
        "\n",
        "### 卷积神经元\n",
        "卷积神经元是一种遵照卷积原理运行的神经元。在现代的图形感知任务中，卷积神经元是最常用的方案。  \n",
        "卷积神经元含有了以下参数：步幅，窗口大小  \n",
        "窗口大小决定了神经元一次性可以看到多少信息，我们将会在初阶编程里看到窗口是如何影响学习到的信息的。  \n",
        "\n",
        "步幅则决定了学习的密度，同时也决定了输出轴的大小。  \n",
        "我们将会在高阶用法中看到两者是如何影响最终信息的特征的。  \n",
        "\n",
        "同时，由于卷积神经元拥有将信息蒸馏简化的特性，故而在涉及大容量数据的网络中，卷积神经元组成的处理单元一般会在前面处理数据。\n",
        "### 循环神经元\n",
        "该神经元在文本序列处理中较为常见。  \n",
        "著名的变体有GRN（门控式循环神经元），LSTM（长短期记忆神经元）。\n",
        "该神经元的内置算法会将上一次的输入与神经元的各项参数（权重，隐藏值等）计算出一个量：状态。与其他神经元不同，它会送入一个平行于神经元处理流的轨道，可以被取出并加入当前的计算。也即是说，这个信息不会受到下一条信息的影响，这使神经元模拟记忆功能。\n",
        ">Tips :  平行于处理流的状态在LSTM神经元中可在任意一个时段提取出来，其他种类的循环神经元将会在某一个固定时刻取出。  \n",
        "\n",
        "\n",
        "我们将在初阶编程阶段时介绍如何给循环神经元准备数据，中阶介绍如何使用，高阶会讲一下如何用它完成文本生成。\n",
        "\n",
        "##优化器，损失函数\n",
        "神经网络的训练离不开优化数学领域的贡献，在论文中，你会经常见到优化器和损失函数的讨论。\n",
        "### 损失函数\n",
        "一种用于计算梯度值的函数。用于计算当前结果与理想结果的差异。这个会指导神经网络的训练流程。  \n",
        "高阶编程时，我们将会学习如何根据损失函数，根据输出计算出原本的输入。  \n",
        "初阶编程阶段会告诉你如何选择损失函数。\n",
        "### 优化器\n",
        "根据梯度信息执行梯度下降的函数，会计算出移动量，之后通过链式求解推导出每一个权重的具体改变  \n",
        "早期使用的是SVG（随机批量优化函数），通过随机选取一批数据，计算移动量，直到找到最小移动量为止。  \n",
        "伪随机优化函数是选取最有可能找到最小值的数据，一般使用贪心算法，A*算法等深度优先搜索算法。收敛更快，随后被用于大型网络的训练之中。   \n",
        "今天的优化器基本上使用SVG，通过搭配其他函数来补足收敛性能不足。  \n",
        "优化器的选择会在初阶实例中讲解。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D6nIYEd6CHBW"
      },
      "source": [
        "#熟悉一下感觉\n",
        "# BUG警告：请勿运行本代码，出现了未知的符号错误，除非你想观看python不是很明确的错误提示（2019.9.6）\n",
        "\n",
        "感受下神经网络训练的感觉是很有必要的，至少可以保证你不会大惊小怪。  \n",
        "提示：按下运行即可执行在本文档中含有的代码。每个Jupyter Notebook都会有不同的配置，请确保你已经查找到了执行代码的方法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCchOHvaEY_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "(train_data, train_label) , (test_data, test_label) = mnist.load_data()\n",
        "model = Sequential()\n",
        "model.add(Dense(512 ,activation='relu' ,input_shape=(None,3,32,32))\n",
        "model.add(Dense(512,activation='relu')\n",
        "model.add(Dense(200,activation='softmax')\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_data,train_label,epochs= 20)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}